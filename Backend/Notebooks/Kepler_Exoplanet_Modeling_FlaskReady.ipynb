{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b928ebf7",
      "metadata": {
        "id": "b928ebf7"
      },
      "source": [
        "# 🟩 Step 1 — Setup & Imports\n",
        "> Initialize environment, import required libraries, and suppress warnings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9ddb90d5",
      "metadata": {
        "id": "9ddb90d5"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Notebook: Kepler_Exoplanet_Modeling_FlaskReady_v2.ipynb\n",
        "Purpose: Full ML workflow + feature selection + outlier handling + Flask integration.\n",
        "\"\"\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    roc_auc_score, f1_score, confusion_matrix, roc_curve\n",
        ")\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b53e782f",
      "metadata": {
        "id": "b53e782f"
      },
      "source": [
        "# 🟦 Step 2 — Define Directory Paths\n",
        "> Create directories for saving models, plots, and results that Flask will access later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "79531e2e",
      "metadata": {
        "id": "79531e2e"
      },
      "outputs": [],
      "source": [
        "BASE_MODEL_DIR = '../static/models'\n",
        "PLOTS_DIR = '../static/plots'\n",
        "RESULTS_DIR = '../static/results'\n",
        "\n",
        "os.makedirs(BASE_MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5208214e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_raw_dataset(file_path):\n",
        "    \"\"\"Load dataset from CSV file.\"\"\"\n",
        "    return pd.read_csv(file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TUNPa4C7QwQE",
      "metadata": {
        "id": "TUNPa4C7QwQE"
      },
      "source": [
        "# 🟨 Step 3 — Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "79MTpxWOQu9E",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "79MTpxWOQu9E",
        "outputId": "8bfcdeb6-8974-42c9-f6e5-6aa1c7dc952c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rowid</th>\n",
              "      <th>kepid</th>\n",
              "      <th>kepoi_name</th>\n",
              "      <th>kepler_name</th>\n",
              "      <th>koi_disposition</th>\n",
              "      <th>koi_vet_stat</th>\n",
              "      <th>koi_vet_date</th>\n",
              "      <th>koi_pdisposition</th>\n",
              "      <th>koi_score</th>\n",
              "      <th>koi_fpflag_nt</th>\n",
              "      <th>...</th>\n",
              "      <th>koi_dicco_mdec</th>\n",
              "      <th>koi_dicco_mdec_err</th>\n",
              "      <th>koi_dicco_msky</th>\n",
              "      <th>koi_dicco_msky_err</th>\n",
              "      <th>koi_dikco_mra</th>\n",
              "      <th>koi_dikco_mra_err</th>\n",
              "      <th>koi_dikco_mdec</th>\n",
              "      <th>koi_dikco_mdec_err</th>\n",
              "      <th>koi_dikco_msky</th>\n",
              "      <th>koi_dikco_msky_err</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>10797460</td>\n",
              "      <td>K00752.01</td>\n",
              "      <td>Kepler-227 b</td>\n",
              "      <td>CONFIRMED</td>\n",
              "      <td>Done</td>\n",
              "      <td>8/16/2018</td>\n",
              "      <td>CANDIDATE</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.170</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.130</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.170</td>\n",
              "      <td>0.320</td>\n",
              "      <td>0.160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>10797460</td>\n",
              "      <td>K00752.02</td>\n",
              "      <td>Kepler-227 c</td>\n",
              "      <td>CONFIRMED</td>\n",
              "      <td>Done</td>\n",
              "      <td>8/16/2018</td>\n",
              "      <td>CANDIDATE</td>\n",
              "      <td>0.969</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.480</td>\n",
              "      <td>0.390</td>\n",
              "      <td>0.360</td>\n",
              "      <td>0.490</td>\n",
              "      <td>0.340</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.730</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>10811496</td>\n",
              "      <td>K00753.01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CANDIDATE</td>\n",
              "      <td>Done</td>\n",
              "      <td>8/16/2018</td>\n",
              "      <td>CANDIDATE</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.034</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.042</td>\n",
              "      <td>0.072</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.071</td>\n",
              "      <td>-0.027</td>\n",
              "      <td>0.074</td>\n",
              "      <td>0.027</td>\n",
              "      <td>0.074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>10848459</td>\n",
              "      <td>K00754.01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FALSE POSITIVE</td>\n",
              "      <td>Done</td>\n",
              "      <td>8/16/2018</td>\n",
              "      <td>FALSE POSITIVE</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.147</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.289</td>\n",
              "      <td>0.079</td>\n",
              "      <td>-0.257</td>\n",
              "      <td>0.072</td>\n",
              "      <td>0.099</td>\n",
              "      <td>0.077</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>10854555</td>\n",
              "      <td>K00755.01</td>\n",
              "      <td>Kepler-664 b</td>\n",
              "      <td>CONFIRMED</td>\n",
              "      <td>Done</td>\n",
              "      <td>8/16/2018</td>\n",
              "      <td>CANDIDATE</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.140</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 141 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   rowid     kepid kepoi_name   kepler_name koi_disposition koi_vet_stat  \\\n",
              "0      1  10797460  K00752.01  Kepler-227 b       CONFIRMED         Done   \n",
              "1      2  10797460  K00752.02  Kepler-227 c       CONFIRMED         Done   \n",
              "2      3  10811496  K00753.01           NaN       CANDIDATE         Done   \n",
              "3      4  10848459  K00754.01           NaN  FALSE POSITIVE         Done   \n",
              "4      5  10854555  K00755.01  Kepler-664 b       CONFIRMED         Done   \n",
              "\n",
              "  koi_vet_date koi_pdisposition  koi_score  koi_fpflag_nt  ...  \\\n",
              "0    8/16/2018        CANDIDATE      1.000              0  ...   \n",
              "1    8/16/2018        CANDIDATE      0.969              0  ...   \n",
              "2    8/16/2018        CANDIDATE      0.000              0  ...   \n",
              "3    8/16/2018   FALSE POSITIVE      0.000              0  ...   \n",
              "4    8/16/2018        CANDIDATE      1.000              0  ...   \n",
              "\n",
              "   koi_dicco_mdec  koi_dicco_mdec_err  koi_dicco_msky koi_dicco_msky_err  \\\n",
              "0           0.200               0.160           0.200              0.170   \n",
              "1           0.000               0.480           0.390              0.360   \n",
              "2          -0.034               0.070           0.042              0.072   \n",
              "3           0.147               0.078           0.289              0.079   \n",
              "4          -0.090               0.180           0.100              0.140   \n",
              "\n",
              "  koi_dikco_mra  koi_dikco_mra_err  koi_dikco_mdec  koi_dikco_mdec_err  \\\n",
              "0         0.080              0.130           0.310               0.170   \n",
              "1         0.490              0.340           0.120               0.730   \n",
              "2         0.002              0.071          -0.027               0.074   \n",
              "3        -0.257              0.072           0.099               0.077   \n",
              "4         0.070              0.180           0.020               0.160   \n",
              "\n",
              "   koi_dikco_msky  koi_dikco_msky_err  \n",
              "0           0.320               0.160  \n",
              "1           0.500               0.450  \n",
              "2           0.027               0.074  \n",
              "3           0.276               0.076  \n",
              "4           0.070               0.200  \n",
              "\n",
              "[5 rows x 141 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset loaded successfully. Shape: (9564, 141)\n"
          ]
        }
      ],
      "source": [
        "df = load_raw_dataset(\"C:\\\\Users\\\\Abdelrahman Bakr\\\\Desktop\\\\me\\\\project\\\\Nasa\\\\Exoplanets-Detection-Using-Machine-Learning\\\\Backend\\\\Note books\\\\Data Sources\\\\Kepler.csv\")\n",
        "\n",
        "display(df.head())\n",
        "\n",
        "print(f\"✅ Dataset loaded successfully. Shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50c8fe88",
      "metadata": {
        "id": "50c8fe88"
      },
      "source": [
        "# 🟩 Step 4 — Build Preprocessor\n",
        "> Define preprocessing pipelines for numeric and categorical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "43ddec7e",
      "metadata": {
        "id": "43ddec7e"
      },
      "outputs": [],
      "source": [
        "def build_preprocessor(numeric_features, categorical_features):\n",
        "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
        "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ])\n",
        "    return preprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9f18a70",
      "metadata": {
        "id": "d9f18a70"
      },
      "source": [
        "# 🟦 Step 5 — Prepare Dataset\n",
        ">select relevant columns, rename them, and prepare target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "aKtFGddkAtty",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKtFGddkAtty",
        "outputId": "06ad7561-7aa3-4917-ccb3-356c802dc0c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9564, 29)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_columns = [\n",
        "    # --- Physical Parameters ---\n",
        "    \"koi_prad\", \"koi_prad_err1\", \"koi_prad_err2\",\n",
        "    \"koi_ror\", \"koi_depth\", \"koi_srho\",\n",
        "\n",
        "    # --- Orbital Parameters ---\n",
        "    \"koi_period\", \"koi_sma\", \"koi_eccen\",\"koi_incl\",\n",
        "    \"koi_duration\", \"koi_ingress\", \"koi_dor\",\n",
        "\n",
        "    # --- Thermal / Habitability ---\n",
        "    \"koi_teq\", \"koi_insol\",\n",
        "\n",
        "    # --- Stellar Properties ---\n",
        "    \"koi_steff\", \"koi_slogg\", \"koi_smet\",\n",
        "    \"koi_srad\", \"koi_smass\", \"koi_sage\",\n",
        "\n",
        "    # --- Detection / Validation ---\n",
        "    \"koi_disposition\", \"koi_pdisposition\", \"koi_score\",\n",
        "    \"koi_model_snr\", \"koi_num_transits\",\n",
        "\n",
        "    # --- Coordinates & brightness ---\n",
        "    \"ra\", \"dec\", \"koi_kepmag\"\n",
        "]\n",
        "\n",
        "df = df[selected_columns]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "PAXVSLnSB_IB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAXVSLnSB_IB",
        "outputId": "6831c4af-7d42-481a-f81a-0a557e14cf53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after selecting columns and attempting to filter dispositions: (9564, 30)\n"
          ]
        }
      ],
      "source": [
        "rename_dict = {\n",
        "    # Physical\n",
        "    \"koi_prad\": \"planet_radius_earth\",\n",
        "    \"koi_prad_err1\": \"planet_radius_err_upper\",\n",
        "    \"koi_prad_err2\": \"planet_radius_err_lower\",\n",
        "    \"koi_ror\": \"radius_ratio_Rp_Rstar\",\n",
        "    \"koi_depth\": \"transit_depth_ppm\",\n",
        "    \"koi_srho\": \"stellar_density_gcm3\",\n",
        "\n",
        "    # Orbital\n",
        "    \"koi_period\": \"orbital_period_days\",\n",
        "    \"koi_sma\": \"semi_major_axis_AU\",\n",
        "    \"koi_eccen\": \"eccentricity\",\n",
        "    \"koi_incl\": \"inclination_deg\",\n",
        "    \"koi_duration\": \"transit_duration_hrs\",\n",
        "    \"koi_ingress\": \"ingress_duration_hrs\",\n",
        "    \"koi_dor\": \"scaled_distance_a_Rstar\",\n",
        "\n",
        "    # Thermal\n",
        "    \"koi_teq\": \"equilibrium_temp_K\",\n",
        "    \"koi_insol\": \"insolation_flux_Earth\",\n",
        "\n",
        "    # Stellar\n",
        "    \"koi_steff\": \"stellar_temp_K\",\n",
        "    \"koi_slogg\": \"stellar_logg\",\n",
        "    \"koi_smet\": \"stellar_metallicity_FeH\",\n",
        "    \"koi_srad\": \"stellar_radius_solar\",\n",
        "    \"koi_smass\": \"stellar_mass_solar\",\n",
        "    \"koi_sage\": \"stellar_age_Gyr\",\n",
        "\n",
        "    # Detection / Validation\n",
        "    \"koi_disposition\": \"final_disposition\",\n",
        "    \"koi_pdisposition\": \"kepler_disposition\",\n",
        "    \"koi_score\": \"disposition_score\",\n",
        "    \"koi_model_snr\": \"signal_to_noise\",\n",
        "    \"koi_num_transits\": \"num_transits\",\n",
        "\n",
        "    # Coordinates & brightness\n",
        "    \"ra\": \"RA_deg\",\n",
        "    \"dec\": \"Dec_deg\",\n",
        "    \"koi_kepmag\": \"kepler_mag\"\n",
        "}\n",
        "\n",
        "\n",
        "if 'koi_disposition' not in selected_columns:\n",
        "    selected_columns.append('koi_disposition') # Add if missing for filtering\n",
        "\n",
        "cols_to_select = [c for c in selected_columns if c in df.columns] # Use df instead of df0\n",
        "df = df[cols_to_select].rename(columns=rename_dict)\n",
        "\n",
        "if 'final_disposition' in df.columns:\n",
        "    # Filter only if the final_disposition column exists\n",
        "    df = df[df['final_disposition'].isin(['CONFIRMED','CANDIDATE','FALSE POSITIVE'])].copy()\n",
        "    df['Target'] = (df['final_disposition'] != 'FALSE POSITIVE').astype(int)\n",
        "else:\n",
        "    # If final_disposition is not in df after renaming, print the warning\n",
        "    print('Warning: final_disposition column not found after selection/renaming. Cannot filter by disposition or create Target.')\n",
        "\n",
        "print('Shape after selecting columns and attempting to filter dispositions:', df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "eiBUuqTqRL1p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eiBUuqTqRL1p",
        "outputId": "a761629f-53a5-4f4f-bfc5-db72688e1de2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "planet_radius_earth         363\n",
              "planet_radius_err_upper     363\n",
              "planet_radius_err_lower     363\n",
              "radius_ratio_Rp_Rstar       363\n",
              "transit_depth_ppm           363\n",
              "stellar_density_gcm3        321\n",
              "orbital_period_days           0\n",
              "semi_major_axis_AU          363\n",
              "eccentricity                363\n",
              "inclination_deg             364\n",
              "transit_duration_hrs          0\n",
              "ingress_duration_hrs       9564\n",
              "scaled_distance_a_Rstar     363\n",
              "equilibrium_temp_K          363\n",
              "insolation_flux_Earth       321\n",
              "stellar_temp_K              363\n",
              "stellar_logg                363\n",
              "stellar_metallicity_FeH     386\n",
              "stellar_radius_solar        363\n",
              "stellar_mass_solar          363\n",
              "stellar_age_Gyr            9564\n",
              "final_disposition             0\n",
              "kepler_disposition            0\n",
              "disposition_score          1510\n",
              "signal_to_noise             363\n",
              "num_transits               1142\n",
              "RA_deg                        0\n",
              "Dec_deg                       0\n",
              "kepler_mag                    1\n",
              "Target                        0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "aM9WePiORaEO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM9WePiORaEO",
        "outputId": "ac60d369-2eef-408b-be90-7851370e81a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numeric columns: ['planet_radius_earth', 'planet_radius_err_upper', 'planet_radius_err_lower', 'radius_ratio_Rp_Rstar', 'transit_depth_ppm', 'stellar_density_gcm3', 'orbital_period_days', 'semi_major_axis_AU', 'eccentricity', 'inclination_deg', 'transit_duration_hrs', 'ingress_duration_hrs', 'scaled_distance_a_Rstar', 'equilibrium_temp_K', 'insolation_flux_Earth', 'stellar_temp_K', 'stellar_logg', 'stellar_metallicity_FeH', 'stellar_radius_solar', 'stellar_mass_solar', 'stellar_age_Gyr', 'disposition_score', 'signal_to_noise', 'num_transits', 'RA_deg', 'Dec_deg', 'kepler_mag', 'Target']\n",
            "\n",
            "Categorical columns: ['final_disposition', 'kepler_disposition']\n"
          ]
        }
      ],
      "source": [
        "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "print(\"Numeric columns:\", numeric_cols)\n",
        "print(\"\\nCategorical columns:\", categorical_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "IjWpeFMaRdEb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjWpeFMaRdEb",
        "outputId": "0cee31ec-3051-4008-cc28-6eb467bc03d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Null values filled for numeric and categorical features.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(9564, 30)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for col in numeric_cols:\n",
        "    if df[col].isnull().any():\n",
        "        df[col].fillna(df[col].mean(), inplace=True)\n",
        "\n",
        "for col in categorical_cols:\n",
        "    if df[col].isnull().any():\n",
        "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "print(\"✅ Null values filled for numeric and categorical features.\")\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4d7a08c",
      "metadata": {
        "id": "c4d7a08c"
      },
      "source": [
        "# 🟨 Step 6 — Preprocessing\n",
        "\n",
        "> Detect and remove outliers using the IQR method for numeric features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "pWtTKi1hRm1n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pWtTKi1hRm1n",
        "outputId": "65438ce2-35d2-4907-cf11-8737096fdfee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "planet_radius_earth        2989\n",
              "planet_radius_err_upper    1788\n",
              "planet_radius_err_lower    1239\n",
              "radius_ratio_Rp_Rstar      8503\n",
              "transit_depth_ppm          6948\n",
              "stellar_density_gcm3       9003\n",
              "orbital_period_days        9564\n",
              "semi_major_axis_AU         3797\n",
              "eccentricity                  1\n",
              "inclination_deg            2261\n",
              "transit_duration_hrs       7834\n",
              "ingress_duration_hrs          0\n",
              "scaled_distance_a_Rstar    6211\n",
              "equilibrium_temp_K         2512\n",
              "insolation_flux_Earth      7802\n",
              "stellar_temp_K             2446\n",
              "stellar_logg               1558\n",
              "stellar_metallicity_FeH     120\n",
              "stellar_radius_solar       2290\n",
              "stellar_mass_solar         1477\n",
              "stellar_age_Gyr               0\n",
              "final_disposition             3\n",
              "kepler_disposition            2\n",
              "disposition_score           651\n",
              "signal_to_noise            2741\n",
              "num_transits               1628\n",
              "RA_deg                     8131\n",
              "Dec_deg                    8195\n",
              "kepler_mag                 3888\n",
              "Target                        2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "xVmZi6CrkbYO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVmZi6CrkbYO",
        "outputId": "54d67209-d230-4476-defb-0dafb28a3dcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after dropping columns: (9564, 25)\n"
          ]
        }
      ],
      "source": [
        "columns_to_drop = ['final_disposition', 'stellar_age_Gyr', 'ingress_duration_hrs', 'eccentricity','orbital_period_days']\n",
        "existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
        "df = df.drop(columns=existing_columns_to_drop, axis=1)\n",
        "print(\"Shape after dropping columns:\", df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "FoLWxMP0Rqra",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoLWxMP0Rqra",
        "outputId": "5c6919cb-bd31-4029-c09f-c08eb486450d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns: ['planet_radius_earth', 'planet_radius_err_upper', 'planet_radius_err_lower', 'radius_ratio_Rp_Rstar', 'transit_depth_ppm', 'stellar_density_gcm3', 'semi_major_axis_AU', 'inclination_deg', 'transit_duration_hrs', 'scaled_distance_a_Rstar', 'equilibrium_temp_K', 'insolation_flux_Earth', 'stellar_temp_K', 'stellar_logg', 'stellar_metallicity_FeH', 'stellar_radius_solar', 'stellar_mass_solar', 'kepler_disposition', 'disposition_score', 'signal_to_noise', 'num_transits', 'RA_deg', 'Dec_deg', 'kepler_mag', 'Target']\n",
            "\n",
            "Missing values per column:\n",
            "planet_radius_earth        0\n",
            "planet_radius_err_upper    0\n",
            "planet_radius_err_lower    0\n",
            "radius_ratio_Rp_Rstar      0\n",
            "transit_depth_ppm          0\n",
            "stellar_density_gcm3       0\n",
            "semi_major_axis_AU         0\n",
            "inclination_deg            0\n",
            "transit_duration_hrs       0\n",
            "scaled_distance_a_Rstar    0\n",
            "equilibrium_temp_K         0\n",
            "insolation_flux_Earth      0\n",
            "stellar_temp_K             0\n",
            "stellar_logg               0\n",
            "stellar_metallicity_FeH    0\n",
            "stellar_radius_solar       0\n",
            "stellar_mass_solar         0\n",
            "kepler_disposition         0\n",
            "disposition_score          0\n",
            "signal_to_noise            0\n",
            "dtype: int64\n",
            "\n",
            "Target distribution:\n",
            "Target\n",
            "0    0.50596\n",
            "1    0.49404\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print('Columns:', df.columns.tolist())\n",
        "print('\\nMissing values per column:')\n",
        "print(df.isnull().sum().sort_values(ascending=False).head(20))\n",
        "print('\\nTarget distribution:')\n",
        "print(df['Target'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b98847a8",
      "metadata": {
        "id": "b98847a8"
      },
      "source": [
        "# 🟩 Step 7 — Split Data & Build Preprocessor\n",
        "> Prepare training and testing datasets and preprocessing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "NOAtWujoSglC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOAtWujoSglC",
        "outputId": "d61ccc4a-0329-4fe9-d1d5-a396d6c8ffc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data splitting complete:\n",
            "X_train shape: (6694, 24)\n",
            "y_train shape: (6694,)\n",
            "X_val shape: (1435, 24)\n",
            "y_val shape: (1435,)\n",
            "X_test shape: (1435, 24)\n",
            "y_test shape: (1435,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop('Target', axis=1)\n",
        "y = df['Target']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(\"Data splitting complete:\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3SVDl7S_S0iF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SVDl7S_S0iF",
        "outputId": "7f81c5e3-b83a-43d6-d047-2b9a0b43a08c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Preprocessor built successfully.\n"
          ]
        }
      ],
      "source": [
        "# Identify numeric and categorical features from the training data\n",
        "numeric_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X_train.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Build the preprocessor\n",
        "preprocessor = build_preprocessor(numeric_features, categorical_features)\n",
        "\n",
        "print(\"✅ Preprocessor built successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d61a1b32",
      "metadata": {
        "id": "d61a1b32"
      },
      "source": [
        "# 🟦 Step 8 — Train Models\n",
        "> Train multiple models and save them for Flask use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "jAdjRqxTTESs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAdjRqxTTESs",
        "outputId": "cd8b199e-a247-45a1-cafb-6cc9e0549b4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RandomForest trained and saved at ../static/models\\RandomForest_pipeline.pkl\n",
            "✅ XGBoost trained and saved at ../static/models\\XGBoost_pipeline.pkl\n",
            "✅ LogisticRegression trained and saved at ../static/models\\LogisticRegression_pipeline.pkl\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42),\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=500)\n",
        "}\n",
        "\n",
        "trained_models = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipe = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    model_path = os.path.join(BASE_MODEL_DIR, f\"{name}_pipeline.pkl\")\n",
        "    joblib.dump(pipe, model_path)\n",
        "\n",
        "    trained_models[name] = pipe\n",
        "    print(f\"✅ {name} trained and saved at {model_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21266477",
      "metadata": {
        "id": "21266477"
      },
      "source": [
        "# 🟩 Step 9 — Evaluate Models and Save Metrics\n",
        "> Evaluate each model and save performance metrics in JSON format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ClTdYjijTYlM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClTdYjijTYlM",
        "outputId": "abd9f4e6-2c73-4a01-b083-91217e8ea635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Metrics saved to ../static/results\\Kepler_metrics.json\n"
          ]
        }
      ],
      "source": [
        "def evaluate_models(models, X_test, y_test):\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_proba = model.predict_proba(X_test)[:, 1]\n",
        "        results[name] = {\n",
        "            \"accuracy\": round(accuracy_score(y_test, y_pred), 3),\n",
        "            \"precision\": round(precision_score(y_test, y_pred), 3),\n",
        "            \"recall\": round(recall_score(y_test, y_pred), 3),\n",
        "            \"f1\": round(f1_score(y_test, y_pred), 3),\n",
        "            \"auc\": round(roc_auc_score(y_test, y_proba), 3)\n",
        "        }\n",
        "    return results\n",
        "\n",
        "def save_metrics(metrics_dict, dataset_name):\n",
        "    \"\"\"Save metrics to JSON for Flask UI.\"\"\"\n",
        "    path = os.path.join(RESULTS_DIR, f\"{dataset_name}_metrics.json\")\n",
        "    with open(path, \"w\") as f:\n",
        "        json.dump(metrics_dict, f, indent=4)\n",
        "    print(f\"✅ Metrics saved to {path}\")\n",
        "\n",
        "results = evaluate_models(trained_models, X_test, y_test)\n",
        "save_metrics(results, \"Kepler\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b71b8519",
      "metadata": {
        "id": "b71b8519"
      },
      "source": [
        "# 🟦 Step 10 — Extract and Save Top 5 Features\n",
        "> Save top features per model for Flask frontend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "va_OcGULTcAA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va_OcGULTcAA",
        "outputId": "c492a622-1962-48cb-f7b6-3a8b3f8e81d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top 5 features for RandomForest saved.\n",
            "✅ Top 5 features for XGBoost saved.\n",
            "✅ Top 5 features for LogisticRegression saved.\n"
          ]
        }
      ],
      "source": [
        "def extract_and_save_feature_importances(model, model_name):\n",
        "    \"\"\"\n",
        "    Extracts and saves the top 5 feature importances (or coefficients) for a given model.\n",
        "\n",
        "    Args:\n",
        "        model: The trained model pipeline.\n",
        "        model_name: The name of the model.\n",
        "    \"\"\"\n",
        "    if hasattr(model.named_steps['model'], \"feature_importances_\"):\n",
        "        importances = model.named_steps['model'].feature_importances_\n",
        "    elif hasattr(model.named_steps['model'], \"coef_\"):\n",
        "        # For linear models like Logistic Regression, coef_ is used\n",
        "        # Ensure coef_ is 1D for multi-class if needed, currently assumes binary\n",
        "        if model.named_steps['model'].coef_.ndim > 1:\n",
        "             importances = abs(model.named_steps['model'].coef_[0])\n",
        "        else:\n",
        "             importances = abs(model.named_steps['model'].coef_)\n",
        "    else:\n",
        "        print(f\"No feature importance available for {model_name}\")\n",
        "        return\n",
        "\n",
        "    # Get feature names after preprocessing from the preprocessor step\n",
        "    try:\n",
        "        processed_feature_names = model.named_steps['preprocessor'].get_feature_names_out()\n",
        "    except AttributeError:\n",
        "        print(f\"Preprocessor in model {model_name} does not have get_feature_names_out method.\")\n",
        "        # Fallback or error handling if get_feature_names_out is not available\n",
        "        return\n",
        "\n",
        "\n",
        "    # Ensure importances and feature names align\n",
        "    if len(importances) != len(processed_feature_names):\n",
        "         print(f\"Mismatch in feature importance length ({len(importances)}) and processed feature names ({len(processed_feature_names)}) for {model_name}\")\n",
        "         return\n",
        "\n",
        "    # Get top 5 feature indices\n",
        "    top_idx = importances.argsort()[-5:][::-1]\n",
        "    top_features = [processed_feature_names[i] for i in top_idx]\n",
        "\n",
        "    with open(os.path.join(RESULTS_DIR, f\"{model_name}_top_features.json\"), \"w\") as f:\n",
        "        json.dump(top_features, f, indent=4)\n",
        "    print(f\"✅ Top 5 features for {model_name} saved.\")\n",
        "\n",
        "for name, model in trained_models.items():\n",
        "    extract_and_save_feature_importances(model, name) # Pass only model and name"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a357c627",
      "metadata": {
        "id": "a357c627"
      },
      "source": [
        "# 🟩 Step 11 — Prediction Function (for Flask API)\n",
        "> Predict class and probability from user-provided input values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ThjoQysQTkgw",
      "metadata": {
        "id": "ThjoQysQTkgw"
      },
      "outputs": [],
      "source": [
        "def predict_from_input(model_name, input_values):\n",
        "    \"\"\"Predict from user input (used by Flask).\"\"\"\n",
        "    model_path = os.path.join(BASE_MODEL_DIR, f\"{model_name}_pipeline.pkl\")\n",
        "    model = joblib.load(model_path)\n",
        "    X = np.array(input_values).reshape(1, -1)\n",
        "    pred = int(model.predict(X)[0])\n",
        "    proba = float(model.predict_proba(X)[0][1])\n",
        "    return {\"prediction\": pred, \"probability\": proba}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f9b18b8",
      "metadata": {
        "id": "1f9b18b8"
      },
      "source": [
        "# 🟦 Step 12 — Final Summary\n",
        "> Confirm successful execution and show saved artifact paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2696a01b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "🔍 MODEL PERFORMANCE RESULTS\n",
            "============================================================\n",
            "\n",
            "📈 PERFORMANCE METRICS:\n",
            "----------------------------------------\n",
            "                    accuracy  precision  recall     f1    auc\n",
            "RandomForest           0.999        1.0   0.997  0.999  0.999\n",
            "XGBoost                0.999        1.0   0.997  0.999  1.000\n",
            "LogisticRegression     0.999        1.0   0.997  0.999  1.000\n",
            "\n",
            "🏆 BEST PERFORMING MODELS:\n",
            "------------------------------\n",
            "Best ACCURACY: RandomForest (0.999)\n",
            "Best PRECISION: RandomForest (1.000)\n",
            "Best RECALL: RandomForest (0.997)\n",
            "Best F1: RandomForest (0.999)\n",
            "Best AUC: XGBoost (1.000)\n",
            "\n",
            "🥇 OVERALL BEST MODEL: RandomForest\n",
            "   F1 Score: 0.999\n",
            "   Accuracy: 0.999\n",
            "   AUC: 0.999\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 📊 Display Model Results and Metrics\n",
        "print(\"=\" * 60)\n",
        "print(\"🔍 MODEL PERFORMANCE RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load and display metrics\n",
        "metrics_file = os.path.join(RESULTS_DIR, \"Kepler_metrics.json\")\n",
        "if os.path.exists(metrics_file):\n",
        "    with open(metrics_file, 'r') as f:\n",
        "        metrics = json.load(f)\n",
        "    \n",
        "    print(\"\\n📈 PERFORMANCE METRICS:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Create a DataFrame for better display\n",
        "    metrics_df = pd.DataFrame(metrics).T\n",
        "    print(metrics_df.round(3))\n",
        "    \n",
        "    # Find best model for each metric\n",
        "    print(\"\\n🏆 BEST PERFORMING MODELS:\")\n",
        "    print(\"-\" * 30)\n",
        "    for metric in ['accuracy', 'precision', 'recall', 'f1', 'auc']:\n",
        "        best_model = metrics_df[metric].idxmax()\n",
        "        best_score = metrics_df[metric].max()\n",
        "        print(f\"Best {metric.upper()}: {best_model} ({best_score:.3f})\")\n",
        "    \n",
        "    # Overall best model (based on F1 score as it balances precision and recall)\n",
        "    best_overall = metrics_df['f1'].idxmax()\n",
        "    print(f\"\\n🥇 OVERALL BEST MODEL: {best_overall}\")\n",
        "    print(f\"   F1 Score: {metrics_df.loc[best_overall, 'f1']:.3f}\")\n",
        "    print(f\"   Accuracy: {metrics_df.loc[best_overall, 'accuracy']:.3f}\")\n",
        "    print(f\"   AUC: {metrics_df.loc[best_overall, 'auc']:.3f}\")\n",
        "    \n",
        "else:\n",
        "    print(\"❌ Metrics file not found!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a6672b40",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 TOP 5 FEATURES FOR EACH MODEL\n",
            "==================================================\n",
            "\n",
            "🎯 RANDOMFOREST - Top 5 Features:\n",
            "------------------------------\n",
            "  1. cat__kepler_disposition_CANDIDATE\n",
            "  2. cat__kepler_disposition_FALSE POSITIVE\n",
            "  3. num__disposition_score\n",
            "  4. num__planet_radius_earth\n",
            "  5. num__planet_radius_err_lower\n",
            "\n",
            "🎯 XGBOOST - Top 5 Features:\n",
            "------------------------------\n",
            "  1. cat__kepler_disposition_CANDIDATE\n",
            "  2. num__insolation_flux_Earth\n",
            "  3. num__signal_to_noise\n",
            "  4. num__disposition_score\n",
            "  5. num__stellar_metallicity_FeH\n",
            "\n",
            "🎯 LOGISTICREGRESSION - Top 5 Features:\n",
            "------------------------------\n",
            "  1. cat__kepler_disposition_CANDIDATE\n",
            "  2. cat__kepler_disposition_FALSE POSITIVE\n",
            "  3. num__disposition_score\n",
            "  4. num__transit_depth_ppm\n",
            "  5. num__stellar_temp_K\n",
            "\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# 🔍 Display Top Features for Each Model\n",
        "print(\"🔍 TOP 5 FEATURES FOR EACH MODEL\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "model_names = [\"RandomForest\", \"XGBoost\", \"LogisticRegression\"]\n",
        "\n",
        "for model_name in model_names:\n",
        "    features_file = os.path.join(RESULTS_DIR, f\"{model_name}_top_features.json\")\n",
        "    if os.path.exists(features_file):\n",
        "        with open(features_file, 'r') as f:\n",
        "            top_features = json.load(f)\n",
        "        \n",
        "        print(f\"\\n🎯 {model_name.upper()} - Top 5 Features:\")\n",
        "        print(\"-\" * 30)\n",
        "        for i, feature in enumerate(top_features, 1):\n",
        "            print(f\"  {i}. {feature}\")\n",
        "    else:\n",
        "        print(f\"\\n❌ Top features file not found for {model_name}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "dcb0b57f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcb0b57f",
        "outputId": "2302ec75-bd63-4931-dfa5-1f15362c576d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Notebook completed successfully.\n",
            "Models saved to: ../static/models\n",
            "Metrics saved to: ../static/results\n",
            "Plots saved to: ../static/plots\n"
          ]
        }
      ],
      "source": [
        "print(\"✅ Notebook completed successfully.\")\n",
        "print(f\"Models saved to: {BASE_MODEL_DIR}\")\n",
        "print(f\"Metrics saved to: {RESULTS_DIR}\")\n",
        "print(f\"Plots saved to: {PLOTS_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67e8614a",
      "metadata": {
        "id": "67e8614a"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "* Applying the IQR-based outlier removal with a multiplier of 10 retained a significant portion of the data, resulting in a DataFrame shape of (5846, 30).\n",
        "* The process successfully removed 3718 outliers while keeping the majority of the data points.\n",
        "* The debug output of the outlier handling function confirmed that using a multiplier of 10 resulted in wider bounds for outlier detection compared to a smaller multiplier, preventing the removal of all data.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "* The choice of outlier handling method and its parameters (like the IQR multiplier) is crucial and highly dependent on the data distribution and the goal of the analysis. Using an overly aggressive outlier removal method can lead to the loss of valuable data or an empty dataset.\n",
        "* Given the successful retention of data after outlier removal, the trained models and their performance metrics can now be analyzed to determine the best model for the classification task. Further steps could involve hyperparameter tuning for the models to potentially improve performance."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
